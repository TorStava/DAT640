{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# G1 Baseline\n",
    "Creating a baseline model for the MSMARCO TREC CAsT dataset using PyTerrier with a basic BM25 model and Random Forest for reranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyterrier as pt\n",
    "import re\n",
    "\n",
    "from pyterrier.measures import *\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "if not pt.started():\n",
    "  pt.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and extract dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *MS MARCO Passages* dataset was downloaded from https://gustav1.ux.uis.no/dat640/msmarco-passage.tar.gz and unpacked in the folder named `data`. Note that this is only needed to do once, so the code has been commented out to avoid running it unnecessarily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘msmarco-passage.tar.gz’ already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !mkdir -p data && \\\n",
    "#   cd data && \\\n",
    "#   wget -nc https://gustav1.ux.uis.no/dat640/msmarco-passage.tar.gz && \\\n",
    "#   tar -xzf msmarco-passage.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the index\n",
    "This is only needed to initially create the index from the collection corpus. It's also possible to download pre-made indices (http://data.terrier.org/msmarco_passage.dataset.html). Since the dataset was provided from a different source than the official there may be some differences, so we decided to build the index ourself on the actual downloaded dataset. Note that it took about 20 minutes to generate the index on a fast workstation (Intel i9 3.7 GHz CPU, 32 GB RAM, and a 3500 MB/s NVMe SSD disk). It could be an advantage to change to Elasticsearch for building and working with the index, especially for large corpus.\n",
    "\n",
    "Ref. https://pyterrier.readthedocs.io/en/latest/terrier-indexing.html#iterdictindexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18:37:34.123 [ForkJoinPool-1-worker-1] WARN org.terrier.structures.indexing.Indexer - Adding an empty document to the index (500080) - further warnings are suppressed\n",
      "18:56:46.730 [ForkJoinPool-1-worker-1] WARN org.terrier.structures.indexing.Indexer - Indexed 5 empty documents\n"
     ]
    }
   ],
   "source": [
    "dataset_path = './data/collection.tsv'\n",
    "\n",
    "\n",
    "def msmarco_generate():\n",
    "    with pt.io.autoopen(dataset_path, 'rt') as corpusfile:\n",
    "        for l in corpusfile:\n",
    "            docno, passage = l.split(\"\\t\")\n",
    "            yield {'docno': docno, 'text': passage}\n",
    "\n",
    "\n",
    "iter_indexer = pt.IterDictIndexer(\n",
    "    \"./index\", blocks=True, overwrite=False, verbose=True, meta={'docno': 20, 'text': 4096})\n",
    "\n",
    "indexref = iter_indexer.index(msmarco_generate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing the index\n",
    "\n",
    "Here we establish a pointer to the generated index.\n",
    "\n",
    "Ref. https://github.com/terrier-org/pyterrier/blob/master/examples/notebooks/retrieval_and_evaluation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 8841823\n",
      "Number of terms: 1170682\n",
      "Number of postings: 215238456\n",
      "Number of fields: 1\n",
      "Number of tokens: 288759529\n",
      "Field names: [text]\n",
      "Positions:   true\n",
      "\n"
     ]
    }
   ],
   "source": [
    "index = pt.IndexFactory.of('./index')\n",
    "print(index.getCollectionStatistics().toString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read topics\n",
    "For the baseline model we use the raw queries without any topic rewriting or context history. Only the most basic cleaning has been performed, by removing any special characters and lowercasing everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4_1</td>\n",
       "      <td>what was the neolithic revolution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4_2</td>\n",
       "      <td>when did it start and end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4_3</td>\n",
       "      <td>why did it start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4_4</td>\n",
       "      <td>what did the neolithic invent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4_5</td>\n",
       "      <td>what tools were used</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>105_5</td>\n",
       "      <td>who named the movement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>105_6</td>\n",
       "      <td>what was the us reaction to it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>105_7</td>\n",
       "      <td>tell me more about the movement of the police ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>105_8</td>\n",
       "      <td>why were they killed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>105_9</td>\n",
       "      <td>what else motivates the black lives matter mov...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       qid                                              query\n",
       "0      4_1                 what was the neolithic revolution \n",
       "1      4_2                         when did it start and end \n",
       "2      4_3                                  why did it start \n",
       "3      4_4                     what did the neolithic invent \n",
       "4      4_5                              what tools were used \n",
       "..     ...                                                ...\n",
       "248  105_5                            who named the movement \n",
       "249  105_6                    what was the us reaction to it \n",
       "250  105_7  tell me more about the movement of the police ...\n",
       "251  105_8                              why were they killed \n",
       "252  105_9  what else motivates the black lives matter mov...\n",
       "\n",
       "[253 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = pd.read_csv('./data/queries_train.csv', usecols=['qid', 'query'])\n",
    "# Remove special characters\n",
    "topics['query'] = topics['query'].apply(lambda x: re.sub(r'\\W', ' ', x).lower())\n",
    "topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read qrels from file\n",
    "Here we read the query relevances that was provided for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>iter</th>\n",
       "      <th>docno</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2253187</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4_1</td>\n",
       "      <td>0</td>\n",
       "      <td>813726</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4_1</td>\n",
       "      <td>0</td>\n",
       "      <td>813729</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2253186</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4_1</td>\n",
       "      <td>0</td>\n",
       "      <td>5414512</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17059</th>\n",
       "      <td>105_9</td>\n",
       "      <td>0</td>\n",
       "      <td>7853976</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17060</th>\n",
       "      <td>105_9</td>\n",
       "      <td>0</td>\n",
       "      <td>7985635</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17061</th>\n",
       "      <td>105_9</td>\n",
       "      <td>0</td>\n",
       "      <td>801480</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17062</th>\n",
       "      <td>105_9</td>\n",
       "      <td>0</td>\n",
       "      <td>801482</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17063</th>\n",
       "      <td>105_9</td>\n",
       "      <td>0</td>\n",
       "      <td>8757526</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17064 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         qid  iter    docno  label\n",
       "0        4_1     0  2253187      1\n",
       "1        4_1     0   813726      2\n",
       "2        4_1     0   813729      2\n",
       "3        4_1     0  2253186      2\n",
       "4        4_1     0  5414512      0\n",
       "...      ...   ...      ...    ...\n",
       "17059  105_9     0  7853976      0\n",
       "17060  105_9     0  7985635      0\n",
       "17061  105_9     0   801480      3\n",
       "17062  105_9     0   801482      1\n",
       "17063  105_9     0  8757526      0\n",
       "\n",
       "[17064 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load query relevance for the training set\n",
    "qrels = pd.read_csv('./data/qrels_train.txt', sep=' ', names=['qid', 'iter', 'docno', 'label'])\n",
    "qrels['docno'] = qrels['docno'].astype(str)\n",
    "qrels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running experiments  \n",
    "\n",
    "In this section we read the training set queries, setup the PyTerrier pipeline, and run BatchRetrival where we return the top 1000 results for each query. The results are finally saved in TREC format.\n",
    "\n",
    "refs.:\n",
    "* https://pyterrier.readthedocs.io/en/latest/terrier-retrieval.html\n",
    "* https://github.com/terrier-org/pyterrier/blob/6698e36f24e02ff3725247e735b791237755085d/examples/experiments/Robust04.ipynb\n",
    "* https://github.com/terrier-org/pyterrier/blob/master/examples/notebooks/retrieval_and_evaluation.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple weighting models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "BM25 = pt.BatchRetrieve(index, num_results=1000, verbose=True, wmodel=\"BM25\")\n",
    "DPH  = pt.BatchRetrieve(index, num_results=1000, verbose=True, wmodel=\"DPH\")\n",
    "PL2  = pt.BatchRetrieve(index, num_results=1000, verbose=True, wmodel=\"PL2\")\n",
    "DLM  = pt.BatchRetrieve(index, num_results=1000, verbose=True, wmodel=\"DirichletLM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BR(BM25): 100%|██████████| 253/253 [01:11<00:00,  3.53q/s]\n",
      "BR(DPH): 100%|██████████| 253/253 [01:10<00:00,  3.57q/s]\n",
      "BR(PL2): 100%|██████████| 253/253 [01:12<00:00,  3.48q/s]\n",
      "BR(DirichletLM): 100%|██████████| 253/253 [01:14<00:00,  3.38q/s]\n"
     ]
    }
   ],
   "source": [
    "# Run experiment with plain BM25 model\n",
    "exp_simple_wm = pt.pipelines.Experiment(\n",
    "    [BM25, DPH, PL2, DLM], \n",
    "    topics, \n",
    "    qrels, \n",
    "    eval_metrics=[R(rel=2)@1000, nDCG@3, AP(rel=2), RR(rel=2)],\n",
    "    names=[\"BM25\", \"DPH\", \"PL2\", \"Dirichlet QL\"], \n",
    "    save_dir='./experiments',\n",
    "    save_mode='overwrite',\n",
    "    filter_by_topics=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>R(rel=2)@1000</th>\n",
       "      <th>nDCG@3</th>\n",
       "      <th>AP(rel=2)</th>\n",
       "      <th>RR(rel=2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.383571</td>\n",
       "      <td>0.095441</td>\n",
       "      <td>0.071540</td>\n",
       "      <td>0.139359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DPH</td>\n",
       "      <td>0.395657</td>\n",
       "      <td>0.097868</td>\n",
       "      <td>0.072007</td>\n",
       "      <td>0.137880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PL2</td>\n",
       "      <td>0.378016</td>\n",
       "      <td>0.095977</td>\n",
       "      <td>0.071830</td>\n",
       "      <td>0.137782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dirichlet QL</td>\n",
       "      <td>0.365456</td>\n",
       "      <td>0.085548</td>\n",
       "      <td>0.074656</td>\n",
       "      <td>0.118252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name  R(rel=2)@1000    nDCG@3  AP(rel=2)  RR(rel=2)\n",
       "0          BM25       0.383571  0.095441   0.071540   0.139359\n",
       "1           DPH       0.395657  0.097868   0.072007   0.137880\n",
       "2           PL2       0.378016  0.095977   0.071830   0.137782\n",
       "3  Dirichlet QL       0.365456  0.085548   0.074656   0.118252"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show results\n",
    "exp_simple_wm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reranking using Random Forest and additional features\n",
    "\n",
    "Here we try to improve the retrieval results by using a Random Forest reranker and additional features from the TF_IDF, PL2, and DLM models.\n",
    "\n",
    "Refs.:\n",
    "* https://pyterrier.readthedocs.io/en/latest/ltr.html\n",
    "* https://github.com/terrier-org/pyterrier/blob/master/examples/notebooks/ltr.ipynb (seems to be outdated, pt.pipelines.LTR_pipeline no longer exists)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "RFR = RandomForestRegressor(n_estimators=400, random_state=42, n_jobs=-1)\n",
    "TF_IDF =  pt.BatchRetrieve(index, num_results=1000, verbose=True, wmodel='TF_IDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BR(BM25): 100%|██████████| 253/253 [01:15<00:00,  3.37q/s]\n",
      "BR(TF_IDF): 100%|██████████| 252/252 [01:07<00:00,  3.71q/s]\n",
      "BR(PL2): 100%|██████████| 252/252 [01:05<00:00,  3.86q/s]\n",
      "BR(DirichletLM): 100%|██████████| 252/252 [01:04<00:00,  3.89q/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 160 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:   26.1s finished\n"
     ]
    }
   ],
   "source": [
    "# Define pipeline and fit reranking model\n",
    "pipe = BM25 >> (pt.transformer.IdentityTransformer() ** TF_IDF ** PL2 ** DLM) >> pt.ltr.apply_learned_model(RFR)\n",
    "pipe.fit(topics, qrels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BR(BM25): 100%|██████████| 253/253 [01:12<00:00,  3.48q/s]\n",
      "BR(TF_IDF): 100%|██████████| 252/252 [01:01<00:00,  4.07q/s]\n",
      "BR(PL2): 100%|██████████| 252/252 [01:04<00:00,  3.91q/s]\n",
      "BR(DirichletLM): 100%|██████████| 252/252 [01:04<00:00,  3.93q/s]\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done 160 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=20)]: Done 400 out of 400 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "# Run experiment\n",
    "exp_rf_rerank = pt.pipelines.Experiment(\n",
    "    [pipe],\n",
    "    topics,\n",
    "    qrels,\n",
    "    eval_metrics=[R(rel=2)@1000, nDCG@3, AP(rel=2), RR(rel=2)],\n",
    "    names=['BM25_TFIDF_PL2_DLM_RF'],\n",
    "    save_dir='./experiments',\n",
    "    save_mode='overwrite',\n",
    "    filter_by_topics=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>R(rel=2)@1000</th>\n",
       "      <th>nDCG@3</th>\n",
       "      <th>AP(rel=2)</th>\n",
       "      <th>RR(rel=2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BM25_TFIDF_PL2_DLM_RF</td>\n",
       "      <td>0.383571</td>\n",
       "      <td>0.407454</td>\n",
       "      <td>0.306488</td>\n",
       "      <td>0.435386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name  R(rel=2)@1000    nDCG@3  AP(rel=2)  RR(rel=2)\n",
       "0  BM25_TFIDF_PL2_DLM_RF       0.383571  0.407454   0.306488   0.435386"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show results\n",
    "exp_rf_rerank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking test queries\n",
    "Using the best baseline model to rank the test queries for posting to the Kaggle competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_1</td>\n",
       "      <td>what is a physician s assistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_2</td>\n",
       "      <td>what are the educational requirements required...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_3</td>\n",
       "      <td>what does it cost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_4</td>\n",
       "      <td>what s the average starting salary in the uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_5</td>\n",
       "      <td>what about in the us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>102_5</td>\n",
       "      <td>how much is owed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>102_6</td>\n",
       "      <td>when will it run out of money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>102_7</td>\n",
       "      <td>wow  what will happen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>102_8</td>\n",
       "      <td>can it be fixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>102_9</td>\n",
       "      <td>how much of an increase</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>248 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       qid                                              query\n",
       "0      1_1                   what is a physician s assistant \n",
       "1      1_2  what are the educational requirements required...\n",
       "2      1_3                                 what does it cost \n",
       "3      1_4      what s the average starting salary in the uk \n",
       "4      1_5                              what about in the us \n",
       "..     ...                                                ...\n",
       "243  102_5                                  how much is owed \n",
       "244  102_6                     when will it run out of money \n",
       "245  102_7                             wow  what will happen \n",
       "246  102_8                                   can it be fixed \n",
       "247  102_9                           how much of an increase \n",
       "\n",
       "[248 rows x 2 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_test = pd.read_csv('./data/queries_test.csv', usecols=['qid', 'query'])\n",
    "# Remove special characters\n",
    "topics_test['query'] = topics_test['query'].apply(lambda x: re.sub(r'\\W', ' ', x).lower())\n",
    "topics_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run batch retrieval, scoring based on nDCG@3. Only the three top-ranked document ID's required for each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BR(BM25): 100%|██████████| 248/248 [01:06<00:00,  3.71q/s]\n",
      "BR(TF_IDF): 100%|██████████| 245/245 [01:01<00:00,  4.01q/s]\n",
      "BR(PL2): 100%|██████████| 245/245 [01:00<00:00,  4.04q/s]\n",
      "BR(DirichletLM): 100%|██████████| 245/245 [00:58<00:00,  4.19q/s]\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done 160 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=20)]: Done 400 out of 400 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "pipe2 = pipe % 3\n",
    "queries_test_results = pipe2.transform(topics_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1_1</td>\n",
       "      <td>5780724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1_1</td>\n",
       "      <td>3951096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1_1</td>\n",
       "      <td>2329378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8193</th>\n",
       "      <td>1_10</td>\n",
       "      <td>1244400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8074</th>\n",
       "      <td>1_10</td>\n",
       "      <td>1852633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223126</th>\n",
       "      <td>99_7</td>\n",
       "      <td>438713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223698</th>\n",
       "      <td>99_7</td>\n",
       "      <td>3180972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224154</th>\n",
       "      <td>99_8</td>\n",
       "      <td>3940798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224044</th>\n",
       "      <td>99_8</td>\n",
       "      <td>290622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224201</th>\n",
       "      <td>99_8</td>\n",
       "      <td>2803390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>735 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         qid    docid\n",
       "7        1_1  5780724\n",
       "8        1_1  3951096\n",
       "19       1_1  2329378\n",
       "8193    1_10  1244400\n",
       "8074    1_10  1852633\n",
       "...      ...      ...\n",
       "223126  99_7   438713\n",
       "223698  99_7  3180972\n",
       "224154  99_8  3940798\n",
       "224044  99_8   290622\n",
       "224201  99_8  2803390\n",
       "\n",
       "[735 rows x 2 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_test_results[['topic_number', 'turn_number']] = queries_test_results['qid'].str.split('_', expand=True)\n",
    "test_res = queries_test_results.sort_values(['topic_number', 'turn_number', 'score'], ascending=[True, True, False])\n",
    "test_res[['qid', 'docid']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to CSV file with headings qid,docid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res[['qid', 'docid']].to_csv('./results/queries_test_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DAT640",
   "language": "python",
   "name": "dat640"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
